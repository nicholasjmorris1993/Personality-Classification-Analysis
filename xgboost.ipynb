{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb00f0e-b45a-475a-ab3f-1647e3f87002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Obtaining dependency information for plotly from https://files.pythonhosted.org/packages/a8/07/72953cf70e3bd3a24cbc3e743e6f8539abe6e3e6d83c3c0c83426eaffd39/plotly-5.18.0-py3-none-any.whl.metadata\n",
      "  Using cached plotly-5.18.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tenacity>=6.2.0 (from plotly)\n",
      "  Obtaining dependency information for tenacity>=6.2.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from plotly) (23.1)\n",
      "Using cached plotly-5.18.0-py3-none-any.whl (15.6 MB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.18.0 tenacity-8.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting py-cpuinfo\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo\n",
      "Successfully installed py-cpuinfo-9.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas-datareader\n",
      "  Using cached pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
      "Collecting lxml (from pandas-datareader)\n",
      "  Obtaining dependency information for lxml from https://files.pythonhosted.org/packages/44/1b/0771c38e65ad23e25368b5e07c920054774b8d12477a4fad116bf500de73/lxml-4.9.3-cp38-cp38-manylinux_2_28_x86_64.whl.metadata\n",
      "  Using cached lxml-4.9.3-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from pandas-datareader) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from pandas-datareader) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from pandas>=0.23->pandas-datareader) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from pandas>=0.23->pandas-datareader) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from pandas>=0.23->pandas-datareader) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from pandas>=0.23->pandas-datareader) (1.24.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests>=2.19.0->pandas-datareader) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests>=2.19.0->pandas-datareader) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests>=2.19.0->pandas-datareader) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests>=2.19.0->pandas-datareader) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>=0.23->pandas-datareader) (1.16.0)\n",
      "Using cached lxml-4.9.3-cp38-cp38-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "Installing collected packages: lxml, pandas-datareader\n",
      "Successfully installed lxml-4.9.3 pandas-datareader-0.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: click in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from nltk) (1.3.0)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/79/33/67c4ed826f5227655225c3feaaecd15afb8453e827334ddae95a7fba07ac/regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from nltk) (4.65.0)\n",
      "Using cached regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.10.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install missing packages\n",
    "%pip install plotly\n",
    "%pip install py-cpuinfo\n",
    "%pip install pandas-datareader\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28211ea4-4ff7-48eb-a395-53442492a061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total RAM: 15.47 GB\n",
      "Available RAM: 14.07 GB\n",
      "Used RAM: 1.14 GB\n",
      "Percentage Usage Of RAM: 9.0%\n",
      "CPU Cores: 4\n",
      "CPU Speed: 2.5000 GHz\n",
      "Total Disk: 24.99 GB\n",
      "Available Disk: 18.69 GB\n",
      "Used Disk: 6.30 GB\n",
      "Percentage Usage Of Disk: 25.2%\n"
     ]
    }
   ],
   "source": [
    "# check system details\n",
    "import os\n",
    "import psutil\n",
    "import cpuinfo\n",
    "\n",
    "ram_info = psutil.virtual_memory()\n",
    "print(f\"Total RAM: {ram_info.total / 1024 / 1024 / 1024:.2f} GB\")\n",
    "print(f\"Available RAM: {ram_info.available / 1024 / 1024 / 1024:.2f} GB\")\n",
    "print(f\"Used RAM: {ram_info.used / 1024 / 1024 / 1024:.2f} GB\")\n",
    "print(f\"Percentage Usage Of RAM: {ram_info.percent}%\")\n",
    "print(f\"CPU Cores: {os.cpu_count()}\")\n",
    "print(f\"CPU Speed: {cpuinfo.get_cpu_info()['hz_actual_friendly']}\")\n",
    "disk_info = psutil.disk_usage(os.getcwd())\n",
    "print(f\"Total Disk: {disk_info.total / 1024 / 1024 / 1024:.2f} GB\")\n",
    "print(f\"Available Disk: {disk_info.free / 1024 / 1024 / 1024:.2f} GB\")\n",
    "print(f\"Used Disk: {disk_info.used / 1024 / 1024 / 1024:.2f} GB\")\n",
    "print(f\"Percentage Usage Of Disk: {disk_info.percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa0ef51-d46b-4ccf-9caa-741ad90c77c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import requirements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from gbm_classifier import Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32da91cf-563e-4206-97d7-6a3c7af2bcfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the data\n",
    "mbti = pd.read_csv(\"mbti_labels.csv\")\n",
    "users = pd.read_csv(\"user_info.csv\")\n",
    "tweets = pd.read_csv(\"user_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc55ab71-63af-4877-a38d-d7987f60c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns from users\n",
    "users = users.drop(columns=[\"id_str\", \"name\", \"screen_name\", \"location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cef2f15-3441-4945-acf3-b1861e17de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only keep the first tweets\n",
    "# tweets = tweets.iloc[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "157116d0-dc99-470d-abd1-12d2df1f540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merge all the tweets together\n",
    "# tweet = pd.DataFrame()\n",
    "# for i in range(tweets.shape[0]):\n",
    "#     Id = tweets[\"id\"][i]\n",
    "#     text = \" \".join(tweets.iloc[i, 1:].astype(str).tolist())\n",
    "#     tweet = pd.concat([\n",
    "#         tweet, \n",
    "#         pd.DataFrame({\"id\": [Id], \"tweet\": [text]}),\n",
    "#     ], axis=\"index\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bb3f629-f1dd-437a-97b9-3f1b55c354eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the data together\n",
    "mbti[\"id\"] = mbti[\"id\"].astype(str)\n",
    "users[\"id\"] = users[\"id\"].astype(str)\n",
    "# tweet[\"id\"] = tweet[\"id\"].astype(str)\n",
    "personality = mbti.merge(right=users, how=\"left\", on=\"id\")\n",
    "# personality = personality.merge(right=tweet, how=\"left\", on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a010638-a2f7-47ba-848e-fbec65b27da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing values with None\n",
    "personality = personality.fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c86b5ea-5ed9-4e11-8a66-1bd894591839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove id\n",
    "personality = personality.drop(columns=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4daa1385-3fc4-44eb-8fa4-8080a90611e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make verified a binary variable\n",
    "personality[\"verified\"] = personality[\"verified\"] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f00bb2cd-e8b1-4b91-a9de-f325f98496ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "personality = personality.sample(frac=1, random_state=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45f9301a-5582-4abd-8e1b-33a9302eb898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the testing data\n",
    "y = personality[[\"mbti_personality\"]]\n",
    "X = personality.drop(columns=\"mbti_personality\")\n",
    "testX = X.tail(int(0.2 * X.shape[0])).reset_index(drop=True)\n",
    "testy = y.tail(int(0.2 * y.shape[0])).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a543694e-96f5-4e1e-ac1c-17e2694f648b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Personality Classification Analysis ----\n",
      "\n",
      "Visualizing The Data:\n",
      "> Plotting Correlations\n",
      "> total_retweet_count vs. average_retweet_count\n",
      "> total_favorite_count vs. average_favorite_count\n",
      "> total_hashtag_count vs. average_hashtag_count\n",
      "> total_url_count vs. average_url_count\n",
      "> total_mentions_count vs. average_mentions_count\n",
      "> total_media_count vs. average_media_count\n",
      "> Plotting followers_count\n",
      "> Plotting friends_count\n",
      "> Plotting listed_count\n",
      "> Plotting favourites_count\n",
      "> Plotting statuses_count\n",
      "> Plotting number_of_quoted_statuses\n",
      "> Plotting number_of_retweeted_statuses\n",
      "> Plotting total_retweet_count\n",
      "> Plotting total_favorite_count\n",
      "> Plotting total_hashtag_count\n",
      "> Plotting total_url_count\n",
      "> Plotting total_mentions_count\n",
      "> Plotting total_media_count\n",
      "> Plotting number_of_tweets_scraped\n",
      "> Plotting average_tweet_length\n",
      "> Plotting average_retweet_count\n",
      "> Plotting average_favorite_count\n",
      "> Plotting average_hashtag_count\n",
      "> Plotting average_url_count\n",
      "> Plotting average_mentions_count\n",
      "> Plotting average_media_count\n",
      "> Plotting verified\n",
      "> mbti_personality vs. verified\n",
      "> followers_count vs. mbti_personality\n",
      "> followers_count vs. verified\n",
      "> friends_count vs. mbti_personality\n",
      "> friends_count vs. verified\n",
      "> listed_count vs. mbti_personality\n",
      "> listed_count vs. verified\n",
      "> favourites_count vs. mbti_personality\n",
      "> favourites_count vs. verified\n",
      "> statuses_count vs. mbti_personality\n",
      "> number_of_quoted_statuses vs. mbti_personality\n",
      "> number_of_quoted_statuses vs. verified\n",
      "> number_of_retweeted_statuses vs. mbti_personality\n",
      "> total_retweet_count vs. mbti_personality\n",
      "> total_retweet_count vs. verified\n",
      "> total_favorite_count vs. mbti_personality\n",
      "> total_favorite_count vs. verified\n",
      "> total_hashtag_count vs. mbti_personality\n",
      "> total_hashtag_count vs. verified\n",
      "> total_url_count vs. mbti_personality\n",
      "> total_url_count vs. verified\n",
      "> total_mentions_count vs. mbti_personality\n",
      "> total_mentions_count vs. verified\n",
      "> total_media_count vs. mbti_personality\n",
      "> total_media_count vs. verified\n",
      "> average_tweet_length vs. mbti_personality\n",
      "> average_retweet_count vs. mbti_personality\n",
      "> average_retweet_count vs. verified\n",
      "> average_favorite_count vs. mbti_personality\n",
      "> average_favorite_count vs. verified\n",
      "> average_hashtag_count vs. mbti_personality\n",
      "> average_hashtag_count vs. verified\n",
      "> average_url_count vs. mbti_personality\n",
      "> average_url_count vs. verified\n",
      "> average_mentions_count vs. mbti_personality\n",
      "> average_mentions_count vs. verified\n",
      "> average_media_count vs. mbti_personality\n",
      "> average_media_count vs. verified\n",
      "8.14 Seconds\n",
      "Model Training:\n",
      "> Transforming The Training Data\n",
      "> Renaming Features\n",
      "> Transforming Text Features\n",
      "> Renaming Features\n",
      "> Removing Constant Features\n",
      "> Selecting Features\n",
      "> Tuning XGBoost\n",
      "> Cross Validating 15 Models\n",
      "> Training The Best Model\n",
      "29.75 Minutes\n",
      "Model Performance:\n",
      "> Transforming The Testing Data\n",
      "> Scoring The Model\n",
      "6.18 Seconds\n",
      "Model Indicators:\n",
      "> Extracting Important Features\n",
      "0.46 Seconds\n",
      "Model Prediction:\n",
      "> Transforming The New Data\n",
      "> Getting Predictions\n",
      "1.6 Seconds\n",
      "Model Monitoring:\n",
      "> Computing Feature Drift\n",
      "10.46 Seconds\n",
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.8467007211538462\n",
      "F1: 0.8290712941943859\n",
      "In Control: 98.8%\n",
      "Confusion Matrix:\n",
      "          enfj      enfp      entj      entp      esfj      esfp      estj      estp      infj      infp      intj      intp      isfj      isfp      istj      istp\n",
      "enfj  0.078078  0.003604  0.001802  0.000601  0.000000  0.000000  0.000000  0.000000  0.001201  0.000000  0.000000  0.002402  0.000000  0.000000  0.000000  0.000601\n",
      "enfp  0.002402  0.084084  0.000601  0.002402  0.000000  0.000000  0.000000  0.001201  0.002402  0.002402  0.000000  0.003604  0.000000  0.000000  0.000000  0.000000\n",
      "entj  0.002402  0.001201  0.067868  0.002402  0.000000  0.000000  0.000000  0.000000  0.001802  0.000000  0.001201  0.003003  0.000000  0.000601  0.000000  0.000601\n",
      "entp  0.003003  0.001802  0.001201  0.063664  0.000000  0.000601  0.000000  0.000000  0.001201  0.000601  0.000000  0.004204  0.000000  0.000000  0.001201  0.001201\n",
      "esfj  0.001201  0.001201  0.000601  0.000000  0.025225  0.000601  0.000000  0.000000  0.001802  0.000000  0.000000  0.002402  0.000000  0.000000  0.000000  0.000000\n",
      "esfp  0.000000  0.000000  0.000000  0.001201  0.000000  0.018018  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "estj  0.000000  0.000000  0.000000  0.001201  0.000000  0.000000  0.019219  0.000000  0.000000  0.000601  0.000000  0.000601  0.000000  0.001201  0.000000  0.000000\n",
      "estp  0.000601  0.000000  0.000000  0.003604  0.000000  0.000601  0.000601  0.010210  0.000000  0.000000  0.000000  0.004204  0.000000  0.001201  0.000000  0.000601\n",
      "infj  0.002402  0.001201  0.000000  0.001802  0.000601  0.000000  0.000000  0.000000  0.098498  0.000601  0.001201  0.003604  0.000000  0.000000  0.000000  0.000000\n",
      "infp  0.003003  0.003604  0.001201  0.000000  0.000000  0.000000  0.000000  0.000601  0.001802  0.093093  0.000601  0.004204  0.000000  0.000601  0.000601  0.000000\n",
      "intj  0.001802  0.004204  0.000000  0.001201  0.000000  0.000000  0.000000  0.000000  0.000601  0.000000  0.096697  0.000601  0.000601  0.000000  0.000000  0.000000\n",
      "intp  0.004805  0.000601  0.001201  0.001201  0.000000  0.000000  0.000000  0.001201  0.000601  0.000000  0.000000  0.079880  0.000601  0.000000  0.000000  0.000000\n",
      "isfj  0.001201  0.001201  0.001201  0.001802  0.000000  0.000601  0.000601  0.000601  0.000000  0.000000  0.000000  0.001802  0.046246  0.000000  0.000000  0.001201\n",
      "isfp  0.000000  0.000000  0.001201  0.001201  0.000000  0.000601  0.000000  0.000000  0.000000  0.000601  0.000601  0.000601  0.000000  0.021021  0.000000  0.001201\n",
      "istj  0.000601  0.000000  0.000000  0.000000  0.000000  0.000000  0.000601  0.000601  0.001802  0.000000  0.000000  0.004204  0.000000  0.000601  0.028829  0.000000\n",
      "istp  0.001201  0.000601  0.000000  0.001201  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.001201  0.000000  0.000000  0.000000  0.016216\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "print(\"\\n---- Personality Classification Analysis ----\\n\")\n",
    "model = Classification(\n",
    "    name=\"XGBoost Without Feature Engineering\", \n",
    "    path=None,\n",
    "    rename=True, \n",
    "    time=False, \n",
    "    text=True,\n",
    "    binary=False, \n",
    "    imputation=False, \n",
    "    variance=True,\n",
    "    atwood=False,\n",
    "    binning=False,\n",
    "    reciprocal=False, \n",
    "    interaction=False, \n",
    "    selection=True,\n",
    "    tune=True,\n",
    "    plots=True,\n",
    ")\n",
    "try:\n",
    "    model.load()  # load the machine learning pipeline\n",
    "    predictions = model.predict(testX)\n",
    "except:\n",
    "    model.explore(personality)\n",
    "    model.validate(X, y)  # build the machine learning pipeline\n",
    "    predictions = model.predict(testX)\n",
    "    print(\"\\nModel Performance:\")\n",
    "    print(f\"Accuracy: {model.accuracy}\")\n",
    "    print(f\"F1: {model.f1}\")\n",
    "    print(f\"In Control: {model.in_control}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    pd.set_option(\"display.width\", 1000)\n",
    "    print(model.confusion / model.confusion.sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b88af05-8286-459b-b34d-0086c4065fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Indicators:\n",
      "1. description_intj\n",
      "2. description_infj\n",
      "3. description_enfp\n",
      "4. description_infp\n",
      "5. description_enfj\n",
      "6. description_entj\n",
      "7. description_intp\n",
      "8. description_entp\n",
      "9. description_isfj\n",
      "10. description_istj\n",
      " \n",
      "Feature Drift:\n",
      "1. average_media_count\n"
     ]
    }
   ],
   "source": [
    "# model diagnostics\n",
    "print(\"Model Indicators:\")\n",
    "for i, indicator in enumerate(model.indicators[\"Indicator\"][:10].tolist()):\n",
    "    print(f\"{i+1}. {indicator}\")\n",
    "print(\" \")\n",
    "print(\"Feature Drift:\")\n",
    "for i, feature in enumerate(model.drift.loc[model.drift[\"pvalue\"] < 0.05, \"Feature\"][:10].tolist()):\n",
    "    print(f\"{i+1}. {feature}\")\n",
    "if model.drift.loc[model.drift[\"pvalue\"] < 0.05].shape[0] == 0:\n",
    "    print(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30b9ca50-06d6-49b7-848b-c0852e302909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8468468468468469\n",
      "F1: 0.8315152346864694\n"
     ]
    }
   ],
   "source": [
    "# score the model\n",
    "accuracy = accuracy_score(\n",
    "    y_true=testy.iloc[:,0].to_numpy(),\n",
    "    y_pred=predictions,\n",
    ")\n",
    "f1 = f1_score(\n",
    "    y_true=testy.iloc[:,0].to_numpy(),\n",
    "    y_pred=predictions,\n",
    "    average=\"macro\",\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da46103b-b661-4234-8a31-9804f9139435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "          enfj      enfp      entj      entp      esfj      esfp      estj      estp      infj      infp      intj      intp      isfj      isfp      istj      istp\n",
      "enfj  0.078078  0.003604  0.001802  0.000601  0.000000  0.000000  0.000000  0.000000  0.001201  0.000000  0.000000  0.002402  0.000000  0.000000  0.000000  0.000601\n",
      "enfp  0.002402  0.084084  0.000601  0.002402  0.000000  0.000000  0.000000  0.001201  0.002402  0.002402  0.000000  0.003604  0.000000  0.000000  0.000000  0.000000\n",
      "entj  0.002402  0.001201  0.067868  0.002402  0.000000  0.000000  0.000000  0.000000  0.001802  0.000000  0.001201  0.003003  0.000000  0.000601  0.000000  0.000601\n",
      "entp  0.003003  0.001802  0.001201  0.063664  0.000000  0.000601  0.000000  0.000000  0.001201  0.000601  0.000000  0.004204  0.000000  0.000000  0.001201  0.001201\n",
      "esfj  0.001201  0.001201  0.000601  0.000000  0.025225  0.000601  0.000000  0.000000  0.001802  0.000000  0.000000  0.002402  0.000000  0.000000  0.000000  0.000000\n",
      "esfp  0.000000  0.000000  0.000000  0.001201  0.000000  0.018018  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "estj  0.000000  0.000000  0.000000  0.001201  0.000000  0.000000  0.019219  0.000000  0.000000  0.000601  0.000000  0.000601  0.000000  0.001201  0.000000  0.000000\n",
      "estp  0.000601  0.000000  0.000000  0.003604  0.000000  0.000601  0.000601  0.010210  0.000000  0.000000  0.000000  0.004204  0.000000  0.001201  0.000000  0.000601\n",
      "infj  0.002402  0.001201  0.000000  0.001802  0.000601  0.000000  0.000000  0.000000  0.098498  0.000601  0.001201  0.003604  0.000000  0.000000  0.000000  0.000000\n",
      "infp  0.003003  0.003604  0.001201  0.000000  0.000000  0.000000  0.000000  0.000601  0.001802  0.093093  0.000601  0.004204  0.000000  0.000601  0.000601  0.000000\n",
      "intj  0.001802  0.004204  0.000000  0.001201  0.000000  0.000000  0.000000  0.000000  0.000601  0.000000  0.096697  0.000601  0.000601  0.000000  0.000000  0.000000\n",
      "intp  0.004805  0.000601  0.001201  0.001201  0.000000  0.000000  0.000000  0.001201  0.000601  0.000000  0.000000  0.079880  0.000601  0.000000  0.000000  0.000000\n",
      "isfj  0.001201  0.001201  0.001201  0.001802  0.000000  0.000601  0.000601  0.000601  0.000000  0.000000  0.000000  0.001802  0.046246  0.000000  0.000000  0.001201\n",
      "isfp  0.000000  0.000000  0.001201  0.001201  0.000000  0.000601  0.000000  0.000000  0.000000  0.000601  0.000601  0.000601  0.000000  0.021021  0.000000  0.001201\n",
      "istj  0.000601  0.000000  0.000000  0.000000  0.000000  0.000000  0.000601  0.000601  0.001802  0.000000  0.000000  0.004204  0.000000  0.000601  0.028829  0.000000\n",
      "istp  0.001201  0.000601  0.000000  0.001201  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.001201  0.000000  0.000000  0.000000  0.016216\n"
     ]
    }
   ],
   "source": [
    "# show the confusion matrix\n",
    "ytest = testy.iloc[:,0].to_numpy()\n",
    "labels = np.unique(np.concatenate((predictions, ytest)))\n",
    "confusion = confusion_matrix(\n",
    "    y_true=ytest,   # rows\n",
    "    y_pred=predictions,  # columns\n",
    "    labels=labels,\n",
    ")\n",
    "confusion = pd.DataFrame(\n",
    "    confusion, \n",
    "    columns=labels, \n",
    "    index=labels,\n",
    ")\n",
    "print(\"Confusion Matrix:\")\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "print(confusion / confusion.sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2226e286-b762-4265-a3de-de9a5561d5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the machine learning pipeline\n",
    "model.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdd600fc-dae1-4f58-9117-0ce0d7fc232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Retraining:\n",
      "> Transforming The Updated Data\n",
      "> Renaming Features\n",
      "> Transforming Text Features\n",
      "> Renaming Features\n",
      "> Removing Constant Features\n",
      "> Selecting Features\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# refit the model to include the test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesty\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sagemaker-studiolab-notebooks/personality-classification/gbm_classifier.py:375\u001b[0m, in \u001b[0;36mClassification.refit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    373\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimpute\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[1;32m    374\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstant1\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m--> 375\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselection1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[1;32m    377\u001b[0m numbers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumbers\u001b[38;5;241m.\u001b[39mfit_transform(X)\n",
      "File \u001b[0;32m~/sagemaker-studiolab-notebooks/personality-classification/gbm_classifier.py:1550\u001b[0m, in \u001b[0;36mFeatureSelector.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m-> 1550\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(X, y)\n",
      "File \u001b[0;32m~/sagemaker-studiolab-notebooks/personality-classification/gbm_classifier.py:1526\u001b[0m, in \u001b[0;36mFeatureSelector.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Selecting Features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1515\u001b[0m tree \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[1;32m   1516\u001b[0m     booster\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgbtree\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1517\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1524\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1525\u001b[0m )\n\u001b[0;32m-> 1526\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;66;03m# get the feature importance to determine indicators of the target\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m importance \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mfeature_importances_\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# refit the model to include the test data\n",
    "model.refit(testX, testy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
